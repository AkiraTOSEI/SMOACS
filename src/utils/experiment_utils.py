import os
import shutil
from typing import Dict, List, NoReturn, Optional

from src.utils.common import get_master_dir


def remove_files_in_directory(directory: str) -> NoReturn:
    """Deletes all files and subdirectories within the specified directory.

    This function recursively deletes all files, symbolic links, and subdirectories within the specified directory.
    It outputs an error message if it fails to delete a file, symbolic link, or directory.

    Args:
        directory (str): The path to the directory from which files and directories are to be deleted.

    Raises:
        Exception: Outputs an error message if there is an issue during file deletion.
    """
    for filename in os.listdir(directory):
        file_path = os.path.join(directory, filename)
        try:
            if os.path.isfile(file_path) or os.path.islink(file_path):
                os.unlink(file_path)  # Remove file or symbolic link
            elif os.path.isdir(file_path):
                shutil.rmtree(file_path)  # Recursively remove directory
        except Exception as e:
            print(f"Failed to delete. File: {file_path}. Error: {e}")


def define_initial_dataset_dir_path(
    crystal_system: Optional[str],
    initial_dataset,
    neutral: bool,
    max_atoms: Optional[int] = 10,
    perovskite_mode: Optional[str] = None,
    perovskite_size: Optional[str] = None,
):
    raw_data_dir = os.path.join(get_master_dir(), "data/raw_data")

    if max_atoms is None:
        max_atoms = 100000000
        max_strings = ""
    else:
        max_strings = f"_max_{max_atoms}atoms"

    if neutral == "neutral":
        suffix = "_neutral"
    elif neutral == "common":
        suffix = "_neutral_common"
    elif neutral == "super_common":
        suffix = "_neutral_super_common"
    elif not neutral:
        suffix = ""
    else:
        raise ValueError(f"Invalid value for neutral: {neutral}")

    if crystal_system is None and initial_dataset == "megnet":
        dir_path = os.path.join(
            raw_data_dir,
            f"initial_candidates_from_{initial_dataset}{max_strings}{suffix}",
        )
        dataset_name = f"{initial_dataset}{max_strings}{suffix}"

    elif crystal_system is None and initial_dataset == "jarvis_supercon":
        dir_path = os.path.join(
            raw_data_dir,
            f"jarvis_supercon_test",
        )
        dataset_name = f"jarvis_supercon_test"
    elif crystal_system == "perovskite":
        if perovskite_size is None:
            size_str = ""
        else:
            perovskite_size in ["2x2x2", "3x3x3", "4x4x4"]
            size_str = f"_{perovskite_size}"
        dataset_name = f"initial_{perovskite_mode}_perovskite{size_str}"
        dir_path = os.path.join(raw_data_dir, dataset_name)

    else:
        raise NotImplementedError
    assert os.path.exists(dir_path), f"{dir_path} does not exist."

    return dir_path, dataset_name


def define_experiment_name(
    model_name: str,
    dataset_name: str,
    optimize_mode: str,
    target_bandgap: float,
    bandgap_margin: float,
    e_form_coef: bool,
    learning_rates: List[float],
    learning_cycles: List[float],
    adding_noise_scale: Optional[float],
    num_steps: int,
    num_graph_update: Optional[float],
):
    lattice_lr, atom_lr, coords_lr = learning_rates
    lattice_cycle, atom_cycle, coords_cycle = learning_cycles
    if lattice_cycle < 1:
        lattice_cycle = 0
    if atom_cycle < 1:
        atom_cycle = 0
    if coords_cycle < 1:
        coords_cycle = 0

    if adding_noise_scale is not None:
        noise_suffix = f"__noise{adding_noise_scale:.4f}"
    else:
        noise_suffix = ""

    if num_graph_update is not None and model_name == "ALIGNN":
        model_name = f"{model_name}up{num_graph_update}"

    exp_name = f"{model_name}__{dataset_name}__bg{target_bandgap:.2f}pm{bandgap_margin:.2f}__EfCoef{e_form_coef}__Atomlr{atom_lr}_c{atom_cycle}__Latticelr{lattice_lr}_c{lattice_cycle}__Coordslr{coords_lr}_c{coords_cycle}__ns{num_steps}{noise_suffix}/{optimize_mode}"
    return exp_name


def extract_conditions(experiment_name: str) -> Dict[str, float]:
    """
    Extracts experimental settings from an experiment name string.

    This function parses the experiment name generated by `define_experiment_name`
    and returns a dictionary of configuration values such as learning rates, cycles,
    target bandgap, use_formation_energy flag, and optimizer settings.

    Args:
        experiment_name (str): A string formatted experiment name like
            'Crystalformer__mydataset__bg2.00pm0.50__EfCoef1-min1.2000__Atomlr0.001_c10__Latticelr0.001_c10__Coordslr0.001_c10__ns500__noise0.0500/pytorch_optimizer'

    Returns:
        dict: Parsed configuration parameters as key-value pairs.
    """
    # 条件を抽出するための正規表現パターン
    # Splitting the name into parts based on '__' and other identifiable markers
    experiment_name, optimize_settings = experiment_name.split("/")
    parts = experiment_name.split("__")
    print(parts)
    model_name = parts[0]
    dataset_name = parts[1]
    bg_info = parts[2].split("bg")[1].split("pm")
    target_bandgap = float(bg_info[0])
    bandgap_margin = float(bg_info[1])
    use_formation_energy = float(parts[3].split("EfCoef")[1])
    atom_info = parts[4].split("Atomlr")[1].split("_c")
    atom_lr = float(atom_info[0])
    atom_cycle = float(atom_info[1])
    lattice_info = parts[5].split("Latticelr")[1].split("_c")
    lattice_lr = float(lattice_info[0])
    lattice_cycle = float(lattice_info[1])
    coords_info = parts[6].split("Coordslr")[1].split("_c")
    coords_lr = float(coords_info[0])
    coords_cycle = float(coords_info[1])
    num_steps = int(parts[7].split("ns")[1])

    # Constructing the dictionary
    result = {
        "model_name": model_name,
        "dataset_name": dataset_name,
        "target_bandgap": target_bandgap,
        "bandgap_margin": bandgap_margin,
        "use_formation_energy": use_formation_energy,
        "atom_lr": atom_lr,
        "atom_cycle": atom_cycle,
        "lattice_lr": lattice_lr,
        "lattice_cycle": lattice_cycle,
        "coords_lr": coords_lr,
        "coords_cycle": coords_cycle,
        "num_steps": num_steps,
        "optimize_settings": optimize_settings,
    }

    # Handling optional noise component if exists
    if len(parts) > 8:
        noise_scale = float(parts[8].split("noise")[1])
        result["adding_noise_scale"] = noise_scale

    return result
